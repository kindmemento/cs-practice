// Gradient Descent is a first-order iterative optimization algorithm used to find the minimum of a function.
// Specifically, in machine learning, it's used to minimize a loss function by iteratively moving towards the steepest descent as defined by the negative of the gradient.
// It's fundamental in training many types of machine learning models.

// Imagine you are developing a machine learning model to predict housing prices based on features like size, location, and number of bedrooms.
// The challenge is to find the best model parameters (weights) that minimze the prediction error.
// Gradient Descent is an iterative optimization algorithm used to find the minimum of a function (in this case, the loss function that measures prediction errors).
