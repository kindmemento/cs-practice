// Gradient Descent is a first-order iterative optimization algorithm used to find the minimum of a function.
// Specifically, in machine learning, it's used to minimize a loss function by iteratively moving towards the steepest descent as defined by the negative of the gradient.
// It's fundamental in training many types of machine learning models.
